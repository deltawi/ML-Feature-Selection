{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical example on how to use this asset\n",
    "\n",
    "\n",
    "## Create your child class \n",
    "The first thing to do is to create a class that inherets the one in MLFeatureSelection module.\n",
    "\n",
    "You need to implement the function **build_model()** and prepare you date to suit your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crossvalidation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building \u001b[36mmlfeatureselection\u001b[0m (\u001b[39;1m2.3\u001b[0m)\n",
      "  - Building \u001b[34msdist\u001b[0m\n",
      "  - Built \u001b[32mmlfeatureselection-2.3.tar.gz\u001b[0m\n",
      "  - Building \u001b[34mwheel\u001b[0m\n",
      "  - Built \u001b[32mmlfeatureselection-2.3-py3-none-any.whl\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install poetry --quiet\n",
    "!poetry build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ../dist/mlfeatureselection-2.3-py3-none-any.whl --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from random import shuffle\n",
    "from feature_selection.selectors import FeatureSelector\n",
    "from logzero import logger\n",
    "import logging\n",
    "\n",
    "class testFeatureSelector(FeatureSelector):\n",
    "    def __init__(self, df, target_col, log_level=logging.INFO, custom_cv=None):\n",
    "        FeatureSelector.__init__(self, df, target_col, log_level)\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Define your model here and return a model instance that implements \"fit\" method\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            'seed': 2020,\n",
    "            'learning_rate': 0.01,\n",
    "            'n_estimators': 400,\n",
    "            'max_depth': 4,\n",
    "            'subsample': 0.7,\n",
    "            'colsample_bytree': 0.7\n",
    "        }\n",
    "        \n",
    "        clf = xgb.XGBClassifier(**params)\n",
    "        return clf\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make you data ready for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>hsc_b</th>\n",
       "      <th>etest_p</th>\n",
       "      <th>workex</th>\n",
       "      <th>degree_p</th>\n",
       "      <th>hsc_p</th>\n",
       "      <th>ssc_b</th>\n",
       "      <th>ssc_p</th>\n",
       "      <th>mba_p</th>\n",
       "      <th>specialisation</th>\n",
       "      <th>hsc_s</th>\n",
       "      <th>status</th>\n",
       "      <th>degree_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.00</td>\n",
       "      <td>91.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.00</td>\n",
       "      <td>58.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.48</td>\n",
       "      <td>78.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.33</td>\n",
       "      <td>66.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.00</td>\n",
       "      <td>68.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.00</td>\n",
       "      <td>57.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.00</td>\n",
       "      <td>52.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.00</td>\n",
       "      <td>59.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.30</td>\n",
       "      <td>73.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.80</td>\n",
       "      <td>55.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  hsc_b  etest_p  workex  degree_p  hsc_p  ssc_b  ssc_p  mba_p  \\\n",
       "0     1.0    1.0     55.0     0.0     58.00  91.00    1.0  67.00  58.80   \n",
       "1     1.0    1.0     86.5     1.0     77.48  78.33    0.0  79.33  66.28   \n",
       "2     1.0    0.0     75.0     0.0     64.00  68.00    0.0  65.00  57.80   \n",
       "3     1.0    0.0     66.0     0.0     52.00  52.00    0.0  56.00  59.43   \n",
       "4     1.0    0.0     96.8     0.0     73.30  73.60    0.0  85.80  55.50   \n",
       "\n",
       "   specialisation  hsc_s  status  degree_t  \n",
       "0             1.0    1.0       1       2.0  \n",
       "1             0.0    2.0       1       2.0  \n",
       "2             0.0    0.0       1       0.0  \n",
       "3             1.0    2.0       0       2.0  \n",
       "4             0.0    1.0       1       0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"Placement_Data_Full_Class.csv\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "list_columns = list(df.columns)\n",
    "shuffle(list_columns)\n",
    "df = df[list_columns]\n",
    "df.loc[df['status'] == 'Placed', 'status'] = 1\n",
    "df.loc[df['status'] == 'Not Placed', 'status'] = 0\n",
    "df[\"status\"]=df[\"status\"].astype('int')\n",
    "df.drop(['salary', 'sl_no'], axis=1, inplace = True)\n",
    "\n",
    "cat_vars = ['workex', 'specialisation', 'gender', 'ssc_b', 'hsc_s', 'hsc_b', \"degree_t\"]\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "            ('OrdEnc', OrdinalEncoder())])\n",
    "\n",
    "df[cat_vars] = categorical_transformer.fit_transform(df[cat_vars])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 201109 16:28:30 selectors:214] Starting score 0.9324150049563251\n",
      "[D 201109 16:28:32 selectors:231] Old score 0.9324150049563251, new score 0.9306507564504265\n",
      "[D 201109 16:28:32 selectors:257] The model is worse ==> keep gender\n",
      "[D 201109 16:28:35 selectors:231] Old score 0.9324150049563251, new score 0.9329875405346678\n",
      "[D 201109 16:28:35 selectors:242] Improvement or nothing changed ==> delete hsc_b\n",
      "[I 201109 16:28:38 selectors:254] New base line score: 0.9329875405346678\n",
      "[D 201109 16:28:38 selectors:147] list of deleted features : ['hsc_b']\n",
      "[D 201109 16:28:41 selectors:231] Old score 0.9329875405346678, new score 0.9358281443645403\n",
      "[D 201109 16:28:41 selectors:242] Improvement or nothing changed ==> delete etest_p\n",
      "[I 201109 16:28:44 selectors:254] New base line score: 0.9358281443645403\n",
      "[D 201109 16:28:44 selectors:147] list of deleted features : ['hsc_b', 'etest_p']\n",
      "[D 201109 16:28:47 selectors:231] Old score 0.9358281443645403, new score 0.9269069589989707\n",
      "[D 201109 16:28:47 selectors:257] The model is worse ==> keep workex\n",
      "[D 201109 16:28:50 selectors:231] Old score 0.9358281443645403, new score 0.9199966184969097\n",
      "[D 201109 16:28:50 selectors:257] The model is worse ==> keep degree_p\n",
      "[D 201109 16:28:54 selectors:231] Old score 0.9358281443645403, new score 0.923620405859707\n",
      "[D 201109 16:28:54 selectors:257] The model is worse ==> keep hsc_p\n",
      "[D 201109 16:28:59 selectors:231] Old score 0.9358281443645403, new score 0.9366942452397804\n",
      "[D 201109 16:28:59 selectors:242] Improvement or nothing changed ==> delete ssc_b\n",
      "[I 201109 16:29:03 selectors:254] New base line score: 0.9366942452397804\n",
      "[D 201109 16:29:03 selectors:147] list of deleted features : ['hsc_b', 'etest_p', 'ssc_b']\n",
      "[D 201109 16:29:07 selectors:231] Old score 0.9366942452397804, new score 0.8761496293780213\n",
      "[D 201109 16:29:07 selectors:257] The model is worse ==> keep ssc_p\n",
      "[D 201109 16:29:11 selectors:231] Old score 0.9366942452397804, new score 0.9254818396458783\n",
      "[D 201109 16:29:11 selectors:257] The model is worse ==> keep mba_p\n",
      "[D 201109 16:29:14 selectors:231] Old score 0.9366942452397804, new score 0.9358413046717441\n",
      "[D 201109 16:29:14 selectors:257] The model is worse ==> keep specialisation\n",
      "[D 201109 16:29:16 selectors:231] Old score 0.9366942452397804, new score 0.9364444547326402\n",
      "[D 201109 16:29:16 selectors:257] The model is worse ==> keep hsc_s\n",
      "[D 201109 16:29:20 selectors:231] Old score 0.9366942452397804, new score 0.9358578356835798\n",
      "[D 201109 16:29:20 selectors:257] The model is worse ==> keep degree_t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of kept feature Index(['gender', 'workex', 'degree_p', 'hsc_p', 'ssc_p', 'mba_p',\n",
      "       'specialisation', 'hsc_s', 'degree_t'],\n",
      "      dtype='object'), 9 out of 12\n"
     ]
    }
   ],
   "source": [
    "f = testFeatureSelector(df=df, target_col='status', log_level=logging.DEBUG)\n",
    "list_kept_features, features_impact = f.feature_selection_cv(small_is_better=False, scoring_metric='roc_auc', cv=20)\n",
    "\n",
    "print(f\"List of kept feature {list_kept_features}, {len(list_kept_features)} out of {df.shape[1] - 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you can notice here is that the AUC improved when dropping some columns from **0.930 --> 0.935**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the features selection with fast_vesion **Only available for xgboost**\n",
    "\n",
    "Use the argument `fast_version=True` in order to activate an accelerator that uses the feature_importance of xgboost to filter out the bottom features ordered by gain. \n",
    "\n",
    "The parameter`nb_ft` will be used to select features to experiment on after the first training of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[D 201109 13:29:28 selectors:139] list of deleted features : ['hsc_s', 'ssc_b']\n",
      "[I 201109 13:29:28 selectors:188] Starting score 0.9319841937570731\n",
      "[D 201109 13:29:31 selectors:201] Old score 0.9319841937570731, new score 0.9339359923791417\n",
      "[D 201109 13:29:31 selectors:204] Improvement or nothing changed ==> delete hsc_b\n",
      "[I 201109 13:29:34 selectors:212] New base line score: 0.9339359923791417\n",
      "[D 201109 13:29:34 selectors:139] list of deleted features : ['hsc_s', 'ssc_b', 'hsc_b']\n",
      "[D 201109 13:29:36 selectors:201] Old score 0.9339359923791417, new score 0.9317701368656561\n",
      "[D 201109 13:29:36 selectors:215] The model is worse ==> keep gender\n",
      "[D 201109 13:29:39 selectors:201] Old score 0.9339359923791417, new score 0.9333070480852012\n",
      "[D 201109 13:29:39 selectors:215] The model is worse ==> keep degree_t\n",
      "[D 201109 13:29:42 selectors:201] Old score 0.9339359923791417, new score 0.9312735225294254\n",
      "[D 201109 13:29:42 selectors:215] The model is worse ==> keep specialisation\n",
      "[D 201109 13:29:45 selectors:201] Old score 0.9339359923791417, new score 0.9262005191248871\n",
      "[D 201109 13:29:45 selectors:215] The model is worse ==> keep workex\n",
      "[D 201109 13:29:49 selectors:201] Old score 0.9339359923791417, new score 0.9380236345291891\n",
      "[D 201109 13:29:49 selectors:204] Improvement or nothing changed ==> delete etest_p\n",
      "[I 201109 13:29:51 selectors:212] New base line score: 0.9380236345291891\n",
      "[D 201109 13:29:51 selectors:139] list of deleted features : ['hsc_s', 'ssc_b', 'hsc_b', 'etest_p']\n",
      "[D 201109 13:29:54 selectors:201] Old score 0.9380236345291891, new score 0.8789283643344085\n",
      "[D 201109 13:29:54 selectors:215] The model is worse ==> keep ssc_p\n",
      "[D 201109 13:29:57 selectors:201] Old score 0.9380236345291891, new score 0.9253760372497309\n",
      "[D 201109 13:29:57 selectors:215] The model is worse ==> keep hsc_p\n",
      "[D 201109 13:30:00 selectors:201] Old score 0.9380236345291891, new score 0.9197558544428921\n",
      "[D 201109 13:30:00 selectors:215] The model is worse ==> keep degree_p\n",
      "[D 201109 13:30:03 selectors:201] Old score 0.9380236345291891, new score 0.9265581953130784\n",
      "[D 201109 13:30:03 selectors:215] The model is worse ==> keep mba_p\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 17s, sys: 17 s, total: 6min 34s\n",
      "Wall time: 39 s\n",
      "List of kept feature Index(['gender', 'degree_t', 'specialisation', 'workex', 'ssc_p', 'hsc_p',\n",
      "       'degree_p', 'mba_p'],\n",
      "      dtype='object'), 8 out of 12\n"
     ]
    }
   ],
   "source": [
    "path = \"Placement_Data_Full_Class.csv\"\n",
    "f = testFeatureSelector(df=df, target_col='status', log_level=logging.DEBUG)\n",
    "%time list_kept_features, features_impact = f.featureSelectionCV(small_is_better=False, scoring_metric='roc_auc', cv=20, fast_version=True, nb_ft=7)\n",
    "\n",
    "print(f\"List of kept feature {list_kept_features}, {len(list_kept_features)} out of {df.shape[1] - 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use your own Cross-Validation function\n",
    "\n",
    "The class must implement split that yields `x_train, y_train, x_test, y_test`\n",
    "In the example bellow, we are stratifying the kfolds using a column \"groups\"\n",
    "\n",
    "**Note**: the framework uses the inner function `split(X, y)`, if other parameters are required they should be added in\n",
    "the custom class like we've donne here with `groups`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "class CustomGroupSplit(StratifiedKFold):\n",
    "    \n",
    "    def __init__(self, groups, n_splits, random_state):\n",
    "        super(CustomGroupSplit, self).__init__(n_splits=n_splits, random_state=random_state)\n",
    "        self.groups = groups\n",
    "    \n",
    "    def split(self, X, y, groups=None):\n",
    "        return super(CustomGroupSplit, self).split(X, y, self.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehditantaoui/anaconda3/envs/persodev/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "[D 201109 13:30:07 selectors:139] list of deleted features : ['hsc_s', 'ssc_b']\n",
      "[I 201109 13:30:07 selectors:188] Starting score 0.9319841937570731\n",
      "[D 201109 13:30:09 selectors:201] Old score 0.9319841937570731, new score 0.9339359923791417\n",
      "[D 201109 13:30:09 selectors:204] Improvement or nothing changed ==> delete hsc_b\n",
      "[I 201109 13:30:11 selectors:212] New base line score: 0.9339359923791417\n",
      "[D 201109 13:30:11 selectors:139] list of deleted features : ['hsc_s', 'ssc_b', 'hsc_b']\n",
      "[D 201109 13:30:14 selectors:201] Old score 0.9339359923791417, new score 0.9317701368656561\n",
      "[D 201109 13:30:14 selectors:215] The model is worse ==> keep gender\n",
      "[D 201109 13:30:16 selectors:201] Old score 0.9339359923791417, new score 0.9333070480852012\n",
      "[D 201109 13:30:16 selectors:215] The model is worse ==> keep degree_t\n",
      "[D 201109 13:30:19 selectors:201] Old score 0.9339359923791417, new score 0.9312735225294254\n",
      "[D 201109 13:30:19 selectors:215] The model is worse ==> keep specialisation\n",
      "[D 201109 13:30:21 selectors:201] Old score 0.9339359923791417, new score 0.9262005191248871\n",
      "[D 201109 13:30:21 selectors:215] The model is worse ==> keep workex\n",
      "[D 201109 13:30:24 selectors:201] Old score 0.9339359923791417, new score 0.9380236345291891\n",
      "[D 201109 13:30:24 selectors:204] Improvement or nothing changed ==> delete etest_p\n",
      "[I 201109 13:30:26 selectors:212] New base line score: 0.9380236345291891\n",
      "[D 201109 13:30:26 selectors:139] list of deleted features : ['hsc_s', 'ssc_b', 'hsc_b', 'etest_p']\n",
      "[D 201109 13:30:28 selectors:201] Old score 0.9380236345291891, new score 0.8789283643344085\n",
      "[D 201109 13:30:28 selectors:215] The model is worse ==> keep ssc_p\n",
      "[D 201109 13:30:31 selectors:201] Old score 0.9380236345291891, new score 0.9253760372497309\n",
      "[D 201109 13:30:31 selectors:215] The model is worse ==> keep hsc_p\n",
      "[D 201109 13:30:34 selectors:201] Old score 0.9380236345291891, new score 0.9197558544428921\n",
      "[D 201109 13:30:34 selectors:215] The model is worse ==> keep degree_p\n",
      "[D 201109 13:30:36 selectors:201] Old score 0.9380236345291891, new score 0.9265581953130784\n",
      "[D 201109 13:30:36 selectors:215] The model is worse ==> keep mba_p\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 32s, sys: 13.1 s, total: 5min 46s\n",
      "Wall time: 33.2 s\n",
      "List of kept feature Index(['gender', 'degree_t', 'specialisation', 'workex', 'ssc_p', 'hsc_p',\n",
      "       'degree_p', 'mba_p'],\n",
      "      dtype='object'), 8 out of 12\n"
     ]
    }
   ],
   "source": [
    "custom_cv = CustomGroupSplit(groups=df.gender, n_splits=20, random_state=2020)\n",
    "    \n",
    "path = \"Placement_Data_Full_Class.csv\"\n",
    "f = testFeatureSelector(df=df, target_col='status', log_level=logging.DEBUG, custom_cv=custom_cv)\n",
    "%time list_kept_features, features_impact = f.featureSelectionCV(small_is_better=False, scoring_metric='roc_auc', cv=20, fast_version=True, nb_ft=7)\n",
    "\n",
    "print(f\"List of kept feature {list_kept_features}, {len(list_kept_features)} out of {df.shape[1] - 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse your features impact "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "ft_impact = pd.DataFrame(features_impact).sort_values('roc_auc gain', ascending=True)\n",
    "_ = plt.figure(figsize=(7,7))\n",
    "plt.barh(ft_impact.feature, ft_impact['roc_auc gain']*100, color=(ft_impact['roc_auc gain']>0).map({True: 'b', False: 'r'}))\n",
    "plt.title(\"Features impact: AUC gain in %\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Sklearn Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from random import shuffle\n",
    "from feature_selection.selectors import FeatureSelector\n",
    "from logzero import logger\n",
    "import logging\n",
    "\n",
    "class testFeatureSelector(FeatureSelector):\n",
    "    def __init__(self, df, target_col, log_level=logging.INFO):\n",
    "        FeatureSelector.__init__(self, df, target_col, log_level)\n",
    "        self.current_col_candidate = ''\n",
    "        \n",
    "    \n",
    "    def action_on_update(self, cols_to_drop):\n",
    "        # Here we add the current col so that it can be removed from the pipeline\n",
    "        self.current_col_candidate = cols_to_drop[0]\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Define your model here and return a model instance that implements \"fit\" method\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            'seed': 2020,\n",
    "            'learning_rate': 0.01,\n",
    "            'n_estimators': 400,\n",
    "            'max_depth': 4,\n",
    "            'subsample': 0.7,\n",
    "            'colsample_bytree': 0.7\n",
    "        }\n",
    "        \n",
    "        cat_vars = ['workex', 'specialisation', 'gender', 'ssc_b', 'hsc_s', 'hsc_b', \"degree_t\"]\n",
    "        num_vars = ['degree_p', 'ssc_p', 'etest_p', 'mba_p', 'hsc_p']\n",
    "        \n",
    "        # Transformer for numerical variables\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())])\n",
    "\n",
    "        # Transformer for categorical variables\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='constant')),\n",
    "            ('OrdEnc', OrdinalEncoder())])\n",
    "\n",
    "        # Here we update the num_vars and cat_vars:\n",
    "        # list_of_deleted_col: inner object refering to columns already deleted\n",
    "        # current_col_candidate: string that refers to the current column being evaluated.\n",
    "        # We make sure that none of the two above are in num_vars nor cat_vars\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numeric_transformer, [col for col in num_vars if (col not in self.list_of_deleted_col) and col != self.current_col_candidate]),\n",
    "                ('cat', categorical_transformer, [col for col in cat_vars if (col not in self.list_of_deleted_col) and col != self.current_col_candidate])])\n",
    "\n",
    "        clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', xgb.XGBClassifier(**params))])\n",
    "        return clf\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make you data ready for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>degree_t</th>\n",
       "      <th>gender</th>\n",
       "      <th>hsc_b</th>\n",
       "      <th>mba_p</th>\n",
       "      <th>workex</th>\n",
       "      <th>hsc_s</th>\n",
       "      <th>specialisation</th>\n",
       "      <th>status</th>\n",
       "      <th>etest_p</th>\n",
       "      <th>ssc_p</th>\n",
       "      <th>degree_p</th>\n",
       "      <th>hsc_p</th>\n",
       "      <th>ssc_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sci&amp;Tech</td>\n",
       "      <td>M</td>\n",
       "      <td>Others</td>\n",
       "      <td>58.80</td>\n",
       "      <td>No</td>\n",
       "      <td>Commerce</td>\n",
       "      <td>Mkt&amp;HR</td>\n",
       "      <td>1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>67.00</td>\n",
       "      <td>58.00</td>\n",
       "      <td>91.00</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sci&amp;Tech</td>\n",
       "      <td>M</td>\n",
       "      <td>Others</td>\n",
       "      <td>66.28</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Science</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>1</td>\n",
       "      <td>86.5</td>\n",
       "      <td>79.33</td>\n",
       "      <td>77.48</td>\n",
       "      <td>78.33</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comm&amp;Mgmt</td>\n",
       "      <td>M</td>\n",
       "      <td>Central</td>\n",
       "      <td>57.80</td>\n",
       "      <td>No</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>65.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>68.00</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sci&amp;Tech</td>\n",
       "      <td>M</td>\n",
       "      <td>Central</td>\n",
       "      <td>59.43</td>\n",
       "      <td>No</td>\n",
       "      <td>Science</td>\n",
       "      <td>Mkt&amp;HR</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>56.00</td>\n",
       "      <td>52.00</td>\n",
       "      <td>52.00</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comm&amp;Mgmt</td>\n",
       "      <td>M</td>\n",
       "      <td>Central</td>\n",
       "      <td>55.50</td>\n",
       "      <td>No</td>\n",
       "      <td>Commerce</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>1</td>\n",
       "      <td>96.8</td>\n",
       "      <td>85.80</td>\n",
       "      <td>73.30</td>\n",
       "      <td>73.60</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    degree_t gender    hsc_b  mba_p workex     hsc_s specialisation  status  \\\n",
       "0   Sci&Tech      M   Others  58.80     No  Commerce         Mkt&HR       1   \n",
       "1   Sci&Tech      M   Others  66.28    Yes   Science        Mkt&Fin       1   \n",
       "2  Comm&Mgmt      M  Central  57.80     No      Arts        Mkt&Fin       1   \n",
       "3   Sci&Tech      M  Central  59.43     No   Science         Mkt&HR       0   \n",
       "4  Comm&Mgmt      M  Central  55.50     No  Commerce        Mkt&Fin       1   \n",
       "\n",
       "   etest_p  ssc_p  degree_p  hsc_p    ssc_b  \n",
       "0     55.0  67.00     58.00  91.00   Others  \n",
       "1     86.5  79.33     77.48  78.33  Central  \n",
       "2     75.0  65.00     64.00  68.00  Central  \n",
       "3     66.0  56.00     52.00  52.00  Central  \n",
       "4     96.8  85.80     73.30  73.60  Central  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"Placement_Data_Full_Class.csv\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "list_columns = list(df.columns)\n",
    "shuffle(list_columns)\n",
    "df = df[list_columns]\n",
    "df.loc[df['status'] == 'Placed', 'status'] = 1\n",
    "df.loc[df['status'] == 'Not Placed', 'status'] = 0\n",
    "df[\"status\"]=df[\"status\"].astype('int')\n",
    "df.drop(['salary', 'sl_no'], axis=1, inplace = True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[D 201109 13:30:36 selectors:161] Working with sklearn pipeline, model type: <class 'xgboost.sklearn.XGBClassifier'>\n",
      "[I 201109 13:30:40 selectors:188] Starting score 0.9328198608838942\n",
      "[D 201109 13:30:43 selectors:201] Old score 0.9328198608838942, new score 0.9316680516101263\n",
      "[D 201109 13:30:43 selectors:215] The model is worse ==> keep degree_t\n",
      "[D 201109 13:30:46 selectors:201] Old score 0.9328198608838942, new score 0.9301846905228321\n",
      "[D 201109 13:30:46 selectors:215] The model is worse ==> keep gender\n",
      "[D 201109 13:30:49 selectors:201] Old score 0.9328198608838942, new score 0.9333692327023206\n",
      "[D 201109 13:30:49 selectors:204] Improvement or nothing changed ==> delete hsc_b\n",
      "[I 201109 13:30:52 selectors:212] New base line score: 0.9333692327023206\n",
      "[D 201109 13:30:52 selectors:139] list of deleted features : ['hsc_b']\n"
     ]
    }
   ],
   "source": [
    "f = testFeatureSelector(df=df, target_col='status', log_level=logging.DEBUG)\n",
    "%time list_kept_features, features_impact = f.featureSelectionCV(small_is_better=False, scoring_metric='roc_auc', cv=20)\n",
    "\n",
    "print(f\"List of kept feature {list_kept_features}, {len(list_kept_features)} out of {df.shape[1] - 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
